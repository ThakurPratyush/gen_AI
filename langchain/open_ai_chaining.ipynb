{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "## LANGSMITH TRACKING\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LC_API_KEY\")\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model  = 'gpt-4o') # if environment not specified then need to use api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x0000013C3F8DBC50> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000013C3EFFB050> root_client=<openai.OpenAI object at 0x0000013C3ED8E9D0> root_async_client=<openai.AsyncOpenAI object at 0x0000013C3F92F3D0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input and response from LLM\n",
    "result = llm.invoke(\"what is gen ai ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a type of artificial intelligence that can create new content, such as text, images, music, or even videos, by learning patterns from existing data. Unlike traditional AI, which is typically used for classification or prediction tasks, generative AI focuses on generating novel outputs that are similar to the examples it was trained on. This technology utilizes models like Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformers, such as GPT (Generative Pre-trained Transformer), which are capable of producing human-like text or other types of data. Generative AI has applications in numerous fields, including content creation, design, entertainment, and more.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 139, 'prompt_tokens': 12, 'total_tokens': 151, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'stop', 'logprobs': None} id='run-e02251af-c0ab-4a2e-85f8-9b62d1ae0a30-0' usage_metadata={'input_tokens': 12, 'output_tokens': 139, 'total_tokens': 151, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a type of artificial intelligence that can create new content, such as text, images, music, or even videos, by learning patterns from existing data. Unlike traditional AI, which is typically used for classification or prediction tasks, generative AI focuses on generating novel outputs that are similar to the examples it was trained on. This technology utilizes models like Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformers, such as GPT (Generative Pre-trained Transformer), which are capable of producing human-like text or other types of data. Generative AI has applications in numerous fields, including content creation, design, entertainment, and more.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 139, 'prompt_tokens': 12, 'total_tokens': 151, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'stop', 'logprobs': None} id='run-e02251af-c0ab-4a2e-85f8-9b62d1ae0a30-0' usage_metadata={'input_tokens': 12, 'output_tokens': 139, 'total_tokens': 151, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## chatprompt template \n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are an AI engineer .Provide me answers based on that'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are an AI engineer .Provide me answers based on that\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "## here we are giving role to system , input is just a placeholer here \n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combining the prompt with the llm model\n",
    "\n",
    "# when given input it goes through prompt and then through llm model\n",
    "chain = prompt|llm\n",
    "\n",
    "response = chain.invoke({\"input\":\"can you tell me about langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"LangChain is a framework designed to facilitate the development of applications that integrate with large language models (LLMs). It provides a suite of tools and abstractions that make it easier for developers to build applications that leverage the capabilities of LLMs, such as OpenAI's GPT or similar models. The framework is particularly focused on enabling applications that involve complex language understanding, generation, and interaction.\\n\\nKey features of LangChain may include:\\n\\n1. **Modular Components**: LangChain provides modular components that can be used to build applications. These components might include interfaces for handling input/output, managing context, and processing language model responses.\\n\\n2. **Context Management**: One of the challenges when working with language models is managing context, especially in conversational applications. LangChain likely provides mechanisms to handle and maintain context over interactions.\\n\\n3. **Integration with LLMs**: It offers seamless integration with various large language models, allowing developers to easily plug in different models based on their application's needs.\\n\\n4. **Tooling and Utilities**: LangChain may come with tooling and utilities that simplify common tasks such as prompt engineering, response parsing, and error handling.\\n\\n5. **Extensibility**: The framework is likely designed to be extensible, enabling developers to customize components or integrate additional functionalities to meet specific application requirements.\\n\\nLangChain is particularly useful for developers looking to build chatbots, virtual assistants, or any application where natural language processing and interaction play a crucial role. It abstracts many of the complexities involved in such tasks, allowing developers to focus on the unique aspects of their application.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 317, 'prompt_tokens': 30, 'total_tokens': 347, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'stop', 'logprobs': None}, id='run-36b9a8c1-12f4-4f0d-b908-6db0f729191e-0', usage_metadata={'input_tokens': 30, 'output_tokens': 317, 'total_tokens': 347, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## str output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|llm|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a suite of tools and services designed to optimize the development and deployment of applications that utilize large language models (LLMs). It addresses the challenges developers face when building with LLMs, such as prompt management, performance evaluation, and iterative improvement. Key features of LangSmith include:\n",
      "\n",
      "1. **Prompt Management:** LangSmith provides tools to manage and version control prompts efficiently. This is crucial for maintaining consistency and tracking changes in applications that rely heavily on prompts to interact with LLMs.\n",
      "\n",
      "2. **Testing and Evaluation:** It offers capabilities to test and evaluate the performance of language models. This includes tracking output quality, ensuring the model meets expected standards, and identifying areas for improvement.\n",
      "\n",
      "3. **Iterative Development:** LangSmith supports an iterative development process, enabling developers to refine their models and prompts iteratively. This helps in quickly adapting to new requirements or improving upon existing functionalities.\n",
      "\n",
      "4. **Integration Tools:** It often includes integration tools that make it easier to connect LLMs into existing workflows, applications, or services, streamlining the deployment process.\n",
      "\n",
      "LangSmith is particularly useful for developers working in environments where rapid prototyping and deployment of natural language processing features are essential.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\":\"can you tell me about langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
